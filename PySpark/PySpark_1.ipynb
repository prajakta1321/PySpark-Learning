{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "F1bbzRcgVkoB"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Default Schema"
      ],
      "metadata": {
        "id": "XmkiLATGXoNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"Example\").getOrCreate()"
      ],
      "metadata": {
        "id": "aZM0-GqVW68X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(1, \"Alice\", 29), (2, \"Alex\", 30)]\n",
        "df = spark.createDataFrame(data, [\"id\", \"name\", \"age\"])\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlYnJ1f5W64_",
        "outputId": "17db066f-189c-4ba9-e4b0-5fead0b8a7ec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+---+\n",
            "| id| name|age|\n",
            "+---+-----+---+\n",
            "|  1|Alice| 29|\n",
            "|  2| Alex| 30|\n",
            "+---+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explicit Schema"
      ],
      "metadata": {
        "id": "z1wZkUsTXqH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
        "\n",
        "schema = StructType([StructField(\"id\", IntegerType(), True),\n",
        "                     StructField(\"name\", StringType(), True),\n",
        "                     StructField(\"age\", IntegerType(), True)])\n",
        "\n",
        "df = spark.createDataFrame(data, schema)\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0i3kd3vW62m",
        "outputId": "a9cea3b1-54ac-4438-f377-59cf50fc19c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            "\n",
            "+---+-----+---+\n",
            "| id| name|age|\n",
            "+---+-----+---+\n",
            "|  1|Alice| 29|\n",
            "|  2| Alex| 30|\n",
            "+---+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# schema as a string\n",
        "data = [(1, \"misty\",12), (2, \"makato\", 14)]\n",
        "schema = \"id INT, name STRING, age INT\"\n",
        "\n",
        "# Corrected line: createDataFrame should be called on the spark session object\n",
        "df_new = spark.createDataFrame(data, schema=schema)\n",
        "df_new.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU0IEW13W60Q",
        "outputId": "9bb89467-2cf8-4f74-ec01-5baf84d0fae9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+\n",
            "| id|  name|age|\n",
            "+---+------+---+\n",
            "|  1| misty| 12|\n",
            "|  2|makato| 14|\n",
            "+---+------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# schema string with float and boolean types\n",
        "schema = \"id INT, name STRING, salary FLOAT, is_active BOOLEAN\"\n",
        "data = [(1, \"Alice\", 50000.0, True), (2, \"Bob\", 60000.50, False)]\n",
        "df = spark.createDataFrame(data, schema = schema)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x11v_-NEW6xi",
        "outputId": "c651de0a-76e0-4392-f7c9-070e168d93ff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+-------+---------+\n",
            "| id| name| salary|is_active|\n",
            "+---+-----+-------+---------+\n",
            "|  1|Alice|50000.0|     true|\n",
            "|  2|  Bob|60000.5|    false|\n",
            "+---+-----+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# schema string with float and boolean types\n",
        "\n",
        "schema = \"id INT, name STRING, salary FLOAT, is_active BOOLEAN\"\n",
        "data = [(1, \"Alice\", 50000.75, True), (2,\"Alex\", 60000.50, False)]\n",
        "spark.createDataFrame(data, schema = schema)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3OVe0rQW6vJ",
        "outputId": "a98697fc-304b-469f-d6bb-840371fd333e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: int, name: string, salary: float, is_active: boolean]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# schema string with date and timestamp\n",
        "\n",
        "from datetime import date, datetime\n",
        "schema = \"id INT, name STRING, date DATE, timestamp TIMESTAMP\"\n",
        "\n",
        "data = [(1, \"alice\", date(2023, 1,15), datetime(2024,3,10,14,30,0)),\n",
        "        (2,\"bob\", date(2023,1,15), datetime(2024,3,10,14,30,0))]\n",
        "\n",
        "spark.createDataFrame(data, schema= schema)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAXKNUAkW6sr",
        "outputId": "e652548d-518c-4cb0-e353-80e5a7603ddd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: int, name: string, date: date, timestamp: timestamp]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using a List of Dictionaries"
      ],
      "metadata": {
        "id": "nbyfaf5Scnzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Example\").getOrCreate()\n",
        "\n",
        "data = [{\"id\":1, \"name\":\"alice\", \"age\":29},\n",
        "        {\"id\":2, \"name\":\"alex\", \"age\":30}]\n",
        "\n",
        "spark.createDataFrame(data)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U7nZ4imW6qS",
        "outputId": "41e94f21-92f0-482a-fb82-528f6984e579"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+-------+---------+\n",
            "| id| name| salary|is_active|\n",
            "+---+-----+-------+---------+\n",
            "|  1|Alice|50000.0|     true|\n",
            "|  2|  Bob|60000.5|    false|\n",
            "+---+-----+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading CSV Files"
      ],
      "metadata": {
        "id": "be_BTBs1dI9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# basic csv files\n",
        "\n",
        "df.spark.readformat(\"csv\").load(\"/path/to/sample.csv\")\n",
        "\n",
        "# csv with header\n",
        "df = spark.read.option(\"header\", True).csv(\"/path/to/sample.csv\")\n",
        "\n",
        "# multiple other options\n",
        "df = spark.read.option(\"inferSchema\", True).option(\"delimiter\",\",\").csv(\"/path/to/sample.csv\")\n",
        "\n",
        "# with defined schema\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, IntegralType\n",
        "\n",
        "schema = StructType([StructField(\"name\", StringType(), True),\n",
        "                     StructField(\"age\", IntegerType(), True)])\n",
        "\n",
        "df.spark.read.format(\"csv\").schema(schema).load(\"/path/to/sample.csv\")"
      ],
      "metadata": {
        "id": "-meG64SpW6n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JSON FILES"
      ],
      "metadata": {
        "id": "nnronjK-hSs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic JSON file\n",
        "df = spark.read.format(\"json\").load(\"/path/to/sample.json\")\n",
        "\n",
        "# JSON with multi-line records\n",
        "df = spark.read.option(\"multiline\", True).json(\"/path/to/sample.json\")\n",
        "\n",
        "# JSON with a defined schema\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "\n",
        "schema = StructType([\n",
        "StructField(\"name\", StringType(), True),\n",
        "StructField(\"age\", IntegerType(), True)])\n",
        "\n",
        "df = spark.read.format(\"json\").schema(schema).load(\"/path/to/sample.json\")"
      ],
      "metadata": {
        "id": "pWhjXUknW6YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSV FILES"
      ],
      "metadata": {
        "id": "mGyOsxoOiMWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic write to CSV\n",
        "df.write.csv(\"/path/to/output_csv\")\n",
        "\n",
        "# With header\n",
        "df.write.option(\"header\", True).csv(\"/path/to/output_csv\")\n",
        "\n",
        "# With multiple options\n",
        "df.write.option(\"header\", True)\\.option(\"delimiter\", \",\")\\.option(\"quote\", '\"')\\.csv(\"/path/to/output_csv\")\n",
        "\n",
        "# Overwrite existing files\n",
        "df.write.mode(\"overwrite\").option(\"header\", True).csv(\"/path/to/output_csv\")\n",
        "\n",
        "# Append to existing data\n",
        "df.write.mode(\"append\").option(\"header\", True).csv(\"/path/to/output_csv\")\n",
        "\n",
        "# Write as a single file\n",
        "df.coalesce(1).write.option(\"header\", True).csv(\"/path/to/output_csv\")"
      ],
      "metadata": {
        "id": "Z2p5xR7AiOAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic JSON write\n",
        "df.write.json(\"/path/to/output_json\")\n",
        "\n",
        "# Overwrite mode\n",
        "df.write.mode(\"overwrite\").json(\"/path/to/output_json\")\n",
        "\n",
        "# Append mode\n",
        "df.write.mode(\"append\").json(\"/path/to/output_json\")\n",
        "\n",
        "# Pretty format (for readability)\n",
        "df.write.option(\"compression\", \"none\").json(\"/path/to/output_json\")\n",
        "\n",
        "# Partitioned output\n",
        "df.write.partitionBy(\"column_name\").json(\"/path/to/output_json\")"
      ],
      "metadata": {
        "id": "2YLmlGgRjNi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parquet Files"
      ],
      "metadata": {
        "id": "Ct8X11_rjRLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Parquet write\n",
        "df.write.parquet(\"/path/to/output_parquet\")\n",
        "\n",
        "# Overwrite mode\n",
        "df.write.mode(\"overwrite\").parquet(\"/path/to/output_parquet\")\n",
        "\n",
        "# Append mode\n",
        "df.write.mode(\"append\").parquet(\"/path/to/output_parquet\")\n",
        "\n",
        "# Partitioned output\n",
        "df.write.partitionBy(\"column_name\").parquet(\"/path/to/output_parquet\")\n",
        "\n",
        "# Compression options (default is snappy)\n",
        "df.write.option(\"compression\", \"gzip\").parquet(\"/path/to/output_parquet\")"
      ],
      "metadata": {
        "id": "YG3wSj09jS7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ORC FILES"
      ],
      "metadata": {
        "id": "xdjlmyAIjlfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic ORC write\n",
        "df.write.orc(\"/path/to/output_orc\")\n",
        "\n",
        "# Overwrite mode\n",
        "df.write.mode(\"overwrite\").orc(\"/path/to/output_orc\")\n",
        "\n",
        "# Append mode\n",
        "df.write.mode(\"append\").orc(\"/path/to/output_orc\")\n",
        "\n",
        "# Partitioned output\n",
        "df.write.partitionBy(\"column_name\").orc(\"/path/to/output_orc\")\n",
        "\n",
        "# Compression options\n",
        "df.write.option(\"compression\", \"zlib\").orc(\"/path/to/output_orc\")"
      ],
      "metadata": {
        "id": "OEU2QYgYjoKL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}